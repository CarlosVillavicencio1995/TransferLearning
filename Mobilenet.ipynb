{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout, BatchNormalization, Input\n",
    "from keras.applications.imagenet_utils import preprocess_input, decode_predictions\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "from re import I\n",
    "from tensorflow.python.keras import backend as K\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__\n",
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "data_entrenamiento = './data/train'\n",
    "data_validacion = './data/validation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "epocas = 50 #numero de veces q se va a iterar sobre el set de datos.\n",
    "width_shape = 224\n",
    "height_shape = 224 # tamano al cual vamos a procesar las imagenes\n",
    "batch_size = 64 #cantidad de imagenes que enviamos a procesar en cada uno de los pasos\n",
    "clases=2 #tipo de imagenes q vamos a enviar\n",
    "lr=0.0005 #determina el tamano de los ajustes que ara nuestra red neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10682 images belonging to 2 classes.\n",
      "<keras.preprocessing.image.DirectoryIterator object at 0x00000163EB0D18E0>\n",
      "Found 3562 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator()\n",
    "valid_datagen = ImageDataGenerator()\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    data_entrenamiento,\n",
    "    target_size=(width_shape, height_shape),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "print(train_generator)\n",
    "validation_generator = valid_datagen.flow_from_directory(\n",
    "    data_validacion,\n",
    "    target_size=(width_shape, height_shape),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Entrenamiento de modelo Mobilenet\n",
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_15 (InputLayer)       [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " conv1 (Conv2D)              (None, 112, 112, 32)      864       \n",
      "                                                                 \n",
      " conv1_bn (BatchNormalizatio  (None, 112, 112, 32)     128       \n",
      " n)                                                              \n",
      "                                                                 \n",
      " conv1_relu (ReLU)           (None, 112, 112, 32)      0         \n",
      "                                                                 \n",
      " conv_dw_1 (DepthwiseConv2D)  (None, 112, 112, 32)     288       \n",
      "                                                                 \n",
      " conv_dw_1_bn (BatchNormaliz  (None, 112, 112, 32)     128       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_1_relu (ReLU)       (None, 112, 112, 32)      0         \n",
      "                                                                 \n",
      " conv_pw_1 (Conv2D)          (None, 112, 112, 64)      2048      \n",
      "                                                                 \n",
      " conv_pw_1_bn (BatchNormaliz  (None, 112, 112, 64)     256       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_1_relu (ReLU)       (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " conv_pad_2 (ZeroPadding2D)  (None, 113, 113, 64)      0         \n",
      "                                                                 \n",
      " conv_dw_2 (DepthwiseConv2D)  (None, 56, 56, 64)       576       \n",
      "                                                                 \n",
      " conv_dw_2_bn (BatchNormaliz  (None, 56, 56, 64)       256       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_2_relu (ReLU)       (None, 56, 56, 64)        0         \n",
      "                                                                 \n",
      " conv_pw_2 (Conv2D)          (None, 56, 56, 128)       8192      \n",
      "                                                                 \n",
      " conv_pw_2_bn (BatchNormaliz  (None, 56, 56, 128)      512       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_2_relu (ReLU)       (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " conv_dw_3 (DepthwiseConv2D)  (None, 56, 56, 128)      1152      \n",
      "                                                                 \n",
      " conv_dw_3_bn (BatchNormaliz  (None, 56, 56, 128)      512       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_3_relu (ReLU)       (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " conv_pw_3 (Conv2D)          (None, 56, 56, 128)       16384     \n",
      "                                                                 \n",
      " conv_pw_3_bn (BatchNormaliz  (None, 56, 56, 128)      512       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_3_relu (ReLU)       (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " conv_pad_4 (ZeroPadding2D)  (None, 57, 57, 128)       0         \n",
      "                                                                 \n",
      " conv_dw_4 (DepthwiseConv2D)  (None, 28, 28, 128)      1152      \n",
      "                                                                 \n",
      " conv_dw_4_bn (BatchNormaliz  (None, 28, 28, 128)      512       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_4_relu (ReLU)       (None, 28, 28, 128)       0         \n",
      "                                                                 \n",
      " conv_pw_4 (Conv2D)          (None, 28, 28, 256)       32768     \n",
      "                                                                 \n",
      " conv_pw_4_bn (BatchNormaliz  (None, 28, 28, 256)      1024      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_4_relu (ReLU)       (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " conv_dw_5 (DepthwiseConv2D)  (None, 28, 28, 256)      2304      \n",
      "                                                                 \n",
      " conv_dw_5_bn (BatchNormaliz  (None, 28, 28, 256)      1024      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_5_relu (ReLU)       (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " conv_pw_5 (Conv2D)          (None, 28, 28, 256)       65536     \n",
      "                                                                 \n",
      " conv_pw_5_bn (BatchNormaliz  (None, 28, 28, 256)      1024      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_5_relu (ReLU)       (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " conv_pad_6 (ZeroPadding2D)  (None, 29, 29, 256)       0         \n",
      "                                                                 \n",
      " conv_dw_6 (DepthwiseConv2D)  (None, 14, 14, 256)      2304      \n",
      "                                                                 \n",
      " conv_dw_6_bn (BatchNormaliz  (None, 14, 14, 256)      1024      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_6_relu (ReLU)       (None, 14, 14, 256)       0         \n",
      "                                                                 \n",
      " conv_pw_6 (Conv2D)          (None, 14, 14, 512)       131072    \n",
      "                                                                 \n",
      " conv_pw_6_bn (BatchNormaliz  (None, 14, 14, 512)      2048      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_6_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_dw_7 (DepthwiseConv2D)  (None, 14, 14, 512)      4608      \n",
      "                                                                 \n",
      " conv_dw_7_bn (BatchNormaliz  (None, 14, 14, 512)      2048      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_7_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_pw_7 (Conv2D)          (None, 14, 14, 512)       262144    \n",
      "                                                                 \n",
      " conv_pw_7_bn (BatchNormaliz  (None, 14, 14, 512)      2048      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_7_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_dw_8 (DepthwiseConv2D)  (None, 14, 14, 512)      4608      \n",
      "                                                                 \n",
      " conv_dw_8_bn (BatchNormaliz  (None, 14, 14, 512)      2048      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_8_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_pw_8 (Conv2D)          (None, 14, 14, 512)       262144    \n",
      "                                                                 \n",
      " conv_pw_8_bn (BatchNormaliz  (None, 14, 14, 512)      2048      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_8_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_dw_9 (DepthwiseConv2D)  (None, 14, 14, 512)      4608      \n",
      "                                                                 \n",
      " conv_dw_9_bn (BatchNormaliz  (None, 14, 14, 512)      2048      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_9_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_pw_9 (Conv2D)          (None, 14, 14, 512)       262144    \n",
      "                                                                 \n",
      " conv_pw_9_bn (BatchNormaliz  (None, 14, 14, 512)      2048      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_9_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_dw_10 (DepthwiseConv2D  (None, 14, 14, 512)      4608      \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_10_bn (BatchNormali  (None, 14, 14, 512)      2048      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_10_relu (ReLU)      (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_pw_10 (Conv2D)         (None, 14, 14, 512)       262144    \n",
      "                                                                 \n",
      " conv_pw_10_bn (BatchNormali  (None, 14, 14, 512)      2048      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_10_relu (ReLU)      (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_dw_11 (DepthwiseConv2D  (None, 14, 14, 512)      4608      \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_11_bn (BatchNormali  (None, 14, 14, 512)      2048      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_11_relu (ReLU)      (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_pw_11 (Conv2D)         (None, 14, 14, 512)       262144    \n",
      "                                                                 \n",
      " conv_pw_11_bn (BatchNormali  (None, 14, 14, 512)      2048      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_11_relu (ReLU)      (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_pad_12 (ZeroPadding2D)  (None, 15, 15, 512)      0         \n",
      "                                                                 \n",
      " conv_dw_12 (DepthwiseConv2D  (None, 7, 7, 512)        4608      \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_12_bn (BatchNormali  (None, 7, 7, 512)        2048      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_12_relu (ReLU)      (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " conv_pw_12 (Conv2D)         (None, 7, 7, 1024)        524288    \n",
      "                                                                 \n",
      " conv_pw_12_bn (BatchNormali  (None, 7, 7, 1024)       4096      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_12_relu (ReLU)      (None, 7, 7, 1024)        0         \n",
      "                                                                 \n",
      " conv_dw_13 (DepthwiseConv2D  (None, 7, 7, 1024)       9216      \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_13_bn (BatchNormali  (None, 7, 7, 1024)       4096      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_13_relu (ReLU)      (None, 7, 7, 1024)        0         \n",
      "                                                                 \n",
      " conv_pw_13 (Conv2D)         (None, 7, 7, 1024)        1048576   \n",
      "                                                                 \n",
      " conv_pw_13_bn (BatchNormali  (None, 7, 7, 1024)       4096      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_13_relu (ReLU)      (None, 7, 7, 1024)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 50176)             0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 128)               6422656   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,668,290\n",
      "Trainable params: 9,646,402\n",
      "Non-trainable params: 21,888\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print('#Entrenamiento de modelo Mobilenet')\n",
    "\n",
    "nb_train_samples = 10682\n",
    "nb_validation_samples = 3562\n",
    "image_input = Input(shape=(width_shape, height_shape, 3))\n",
    "m_MobileNet = MobileNet(input_tensor=image_input, include_top=False,weights='imagenet')\n",
    "last_layer = m_MobileNet.layers[-1].output\n",
    "x= Flatten(name='flatten')(last_layer)\n",
    "x = Dense(128, activation='relu', name='fc1')(x)\n",
    "x=Dropout(0.3)(x)\n",
    "x = Dense(128, activation='relu', name='fc2')(x)\n",
    "x=Dropout(0.3)(x)\n",
    "out = Dense(clases, activation='softmax', name='output')(x)\n",
    "custom_model = Model(image_input, out)\n",
    "custom_model.summary()\n",
    "custom_model.compile(loss='categorical_crossentropy',optimizer='adadelta',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "166/166 [==============================] - 113s 621ms/step - loss: 0.9522 - accuracy: 0.5947 - val_loss: 0.4745 - val_accuracy: 0.7898\n",
      "Epoch 2/50\n",
      "166/166 [==============================] - 73s 439ms/step - loss: 0.6087 - accuracy: 0.7241 - val_loss: 0.3307 - val_accuracy: 0.8713\n",
      "Epoch 3/50\n",
      "166/166 [==============================] - 73s 440ms/step - loss: 0.4884 - accuracy: 0.7846 - val_loss: 0.2734 - val_accuracy: 0.8929\n",
      "Epoch 4/50\n",
      "166/166 [==============================] - 72s 435ms/step - loss: 0.4040 - accuracy: 0.8316 - val_loss: 0.2420 - val_accuracy: 0.9017\n",
      "Epoch 5/50\n",
      "166/166 [==============================] - 72s 434ms/step - loss: 0.3478 - accuracy: 0.8584 - val_loss: 0.2228 - val_accuracy: 0.9148\n",
      "Epoch 6/50\n",
      "166/166 [==============================] - 72s 431ms/step - loss: 0.3262 - accuracy: 0.8701 - val_loss: 0.2107 - val_accuracy: 0.9210\n",
      "Epoch 7/50\n",
      "166/166 [==============================] - 72s 431ms/step - loss: 0.2933 - accuracy: 0.8892 - val_loss: 0.2044 - val_accuracy: 0.9207\n",
      "Epoch 8/50\n",
      "166/166 [==============================] - 73s 440ms/step - loss: 0.2661 - accuracy: 0.8953 - val_loss: 0.1988 - val_accuracy: 0.9244\n",
      "Epoch 9/50\n",
      "166/166 [==============================] - 72s 433ms/step - loss: 0.2549 - accuracy: 0.9064 - val_loss: 0.1954 - val_accuracy: 0.9264\n",
      "Epoch 10/50\n",
      "166/166 [==============================] - 69s 412ms/step - loss: 0.2468 - accuracy: 0.9050 - val_loss: 0.1928 - val_accuracy: 0.9253\n",
      "Epoch 11/50\n",
      "166/166 [==============================] - 67s 405ms/step - loss: 0.2326 - accuracy: 0.9121 - val_loss: 0.1898 - val_accuracy: 0.9259\n",
      "Epoch 12/50\n",
      "166/166 [==============================] - 68s 409ms/step - loss: 0.2283 - accuracy: 0.9136 - val_loss: 0.1843 - val_accuracy: 0.9281\n",
      "Epoch 13/50\n",
      "166/166 [==============================] - 68s 408ms/step - loss: 0.2165 - accuracy: 0.9168 - val_loss: 0.1819 - val_accuracy: 0.9304\n",
      "Epoch 14/50\n",
      "166/166 [==============================] - 70s 418ms/step - loss: 0.2060 - accuracy: 0.9227 - val_loss: 0.1819 - val_accuracy: 0.9312\n",
      "Epoch 15/50\n",
      "166/166 [==============================] - 72s 430ms/step - loss: 0.2012 - accuracy: 0.9235 - val_loss: 0.1766 - val_accuracy: 0.9338\n",
      "Epoch 16/50\n",
      "166/166 [==============================] - 73s 439ms/step - loss: 0.1965 - accuracy: 0.9259 - val_loss: 0.1761 - val_accuracy: 0.9332\n",
      "Epoch 17/50\n",
      "166/166 [==============================] - 73s 438ms/step - loss: 0.1850 - accuracy: 0.9301 - val_loss: 0.1763 - val_accuracy: 0.9330\n",
      "Epoch 18/50\n",
      "166/166 [==============================] - 73s 439ms/step - loss: 0.1847 - accuracy: 0.9289 - val_loss: 0.1763 - val_accuracy: 0.9344\n",
      "Epoch 19/50\n",
      "166/166 [==============================] - 69s 415ms/step - loss: 0.1845 - accuracy: 0.9304 - val_loss: 0.1724 - val_accuracy: 0.9358\n",
      "Epoch 20/50\n",
      "166/166 [==============================] - 68s 406ms/step - loss: 0.1745 - accuracy: 0.9316 - val_loss: 0.1738 - val_accuracy: 0.9335\n",
      "Epoch 21/50\n",
      "166/166 [==============================] - 68s 408ms/step - loss: 0.1647 - accuracy: 0.9328 - val_loss: 0.1719 - val_accuracy: 0.9361\n",
      "Epoch 22/50\n",
      "166/166 [==============================] - 66s 399ms/step - loss: 0.1655 - accuracy: 0.9354 - val_loss: 0.1684 - val_accuracy: 0.9361\n",
      "Epoch 23/50\n",
      "166/166 [==============================] - 70s 422ms/step - loss: 0.1674 - accuracy: 0.9341 - val_loss: 0.1706 - val_accuracy: 0.9364\n",
      "Epoch 24/50\n",
      "166/166 [==============================] - 67s 401ms/step - loss: 0.1571 - accuracy: 0.9390 - val_loss: 0.1709 - val_accuracy: 0.9361\n",
      "Epoch 25/50\n",
      "166/166 [==============================] - 69s 413ms/step - loss: 0.1501 - accuracy: 0.9403 - val_loss: 0.1693 - val_accuracy: 0.9372\n",
      "Epoch 26/50\n",
      "166/166 [==============================] - 69s 412ms/step - loss: 0.1444 - accuracy: 0.9462 - val_loss: 0.1693 - val_accuracy: 0.9375\n",
      "Epoch 27/50\n",
      "166/166 [==============================] - 66s 398ms/step - loss: 0.1452 - accuracy: 0.9425 - val_loss: 0.1675 - val_accuracy: 0.9384\n",
      "Epoch 28/50\n",
      "166/166 [==============================] - 67s 404ms/step - loss: 0.1406 - accuracy: 0.9436 - val_loss: 0.1677 - val_accuracy: 0.9378\n",
      "Epoch 29/50\n",
      "166/166 [==============================] - 66s 399ms/step - loss: 0.1385 - accuracy: 0.9462 - val_loss: 0.1681 - val_accuracy: 0.9381\n",
      "Epoch 30/50\n",
      "166/166 [==============================] - 66s 396ms/step - loss: 0.1378 - accuracy: 0.9452 - val_loss: 0.1637 - val_accuracy: 0.9392\n",
      "Epoch 31/50\n",
      "166/166 [==============================] - 66s 394ms/step - loss: 0.1307 - accuracy: 0.9486 - val_loss: 0.1692 - val_accuracy: 0.9381\n",
      "Epoch 32/50\n",
      "166/166 [==============================] - 68s 411ms/step - loss: 0.1337 - accuracy: 0.9476 - val_loss: 0.1699 - val_accuracy: 0.9389\n",
      "Epoch 33/50\n",
      "166/166 [==============================] - 71s 427ms/step - loss: 0.1345 - accuracy: 0.9469 - val_loss: 0.1677 - val_accuracy: 0.9392\n",
      "Epoch 34/50\n",
      "166/166 [==============================] - 68s 410ms/step - loss: 0.1197 - accuracy: 0.9526 - val_loss: 0.1703 - val_accuracy: 0.9395\n",
      "Epoch 35/50\n",
      "166/166 [==============================] - 70s 419ms/step - loss: 0.1217 - accuracy: 0.9517 - val_loss: 0.1668 - val_accuracy: 0.9406\n",
      "Epoch 36/50\n",
      "166/166 [==============================] - 71s 426ms/step - loss: 0.1134 - accuracy: 0.9561 - val_loss: 0.1675 - val_accuracy: 0.9423\n",
      "Epoch 37/50\n",
      "166/166 [==============================] - 67s 402ms/step - loss: 0.1130 - accuracy: 0.9539 - val_loss: 0.1680 - val_accuracy: 0.9412\n",
      "Epoch 38/50\n",
      "166/166 [==============================] - 71s 428ms/step - loss: 0.1214 - accuracy: 0.9509 - val_loss: 0.1691 - val_accuracy: 0.9406\n",
      "Epoch 39/50\n",
      "166/166 [==============================] - 71s 424ms/step - loss: 0.1155 - accuracy: 0.9539 - val_loss: 0.1654 - val_accuracy: 0.9426\n",
      "Epoch 40/50\n",
      "166/166 [==============================] - 68s 410ms/step - loss: 0.1115 - accuracy: 0.9565 - val_loss: 0.1672 - val_accuracy: 0.9426\n",
      "Epoch 41/50\n",
      "166/166 [==============================] - 70s 422ms/step - loss: 0.1027 - accuracy: 0.9595 - val_loss: 0.1691 - val_accuracy: 0.9418\n",
      "Epoch 42/50\n",
      "166/166 [==============================] - 72s 430ms/step - loss: 0.1093 - accuracy: 0.9557 - val_loss: 0.1702 - val_accuracy: 0.9426\n",
      "Epoch 43/50\n",
      "166/166 [==============================] - 71s 426ms/step - loss: 0.1024 - accuracy: 0.9590 - val_loss: 0.1666 - val_accuracy: 0.9429\n",
      "Epoch 44/50\n",
      "166/166 [==============================] - 70s 421ms/step - loss: 0.1043 - accuracy: 0.9583 - val_loss: 0.1679 - val_accuracy: 0.9432\n",
      "Epoch 45/50\n",
      "166/166 [==============================] - 71s 427ms/step - loss: 0.0965 - accuracy: 0.9617 - val_loss: 0.1648 - val_accuracy: 0.9443\n",
      "Epoch 46/50\n",
      "166/166 [==============================] - 70s 422ms/step - loss: 0.0971 - accuracy: 0.9609 - val_loss: 0.1670 - val_accuracy: 0.9446\n",
      "Epoch 47/50\n",
      "166/166 [==============================] - 69s 415ms/step - loss: 0.0929 - accuracy: 0.9623 - val_loss: 0.1687 - val_accuracy: 0.9432\n",
      "Epoch 48/50\n",
      "166/166 [==============================] - 67s 400ms/step - loss: 0.0906 - accuracy: 0.9637 - val_loss: 0.1695 - val_accuracy: 0.9426\n",
      "Epoch 49/50\n",
      "166/166 [==============================] - 66s 398ms/step - loss: 0.0898 - accuracy: 0.9652 - val_loss: 0.1705 - val_accuracy: 0.9418\n",
      "Epoch 50/50\n",
      "166/166 [==============================] - 69s 413ms/step - loss: 0.0869 - accuracy: 0.9660 - val_loss: 0.1679 - val_accuracy: 0.9446\n"
     ]
    }
   ],
   "source": [
    "model_history = custom_model.fit(\n",
    "    train_generator,\n",
    "    epochs=epocas,\n",
    "    validation_data=validation_generator,\n",
    "    steps_per_epoch=nb_train_samples//batch_size,\n",
    "    validation_steps=nb_validation_samples//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_model.save(\"./modelos/model_Mobilenet.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotTraining(hist, epochs, typeData):\n",
    "    if typeData == \"loss\":\n",
    "        plt.figure(1, figsize=(10, 5))\n",
    "        yc = hist.history['loss']\n",
    "        xc = range(epochs)\n",
    "        plt.ylabel('Loss', fontsize=24)\n",
    "        plt.plot(xc, yc, '-r', label='Loss Training')\n",
    "    if typeData == \"accuracy\":\n",
    "        plt.figure(2, figsize=(10, 5))\n",
    "        yc = hist.history['accuracy']\n",
    "        for i in range(0, len(yc)):\n",
    "            yc[i] = 100 * yc[i]\n",
    "        xc = range(epochs)\n",
    "        plt.ylabel('Accuracy (%)', fontsize=24)\n",
    "        plt.plot(xc, yc, '-r', label='Accuracy Training')\n",
    "    if typeData == \"val_loss\":\n",
    "        plt.figure(1, figsize=(10, 5))\n",
    "        yc = hist.history['val_loss']\n",
    "        xc = range(epochs)\n",
    "        plt.ylabel('Loss', fontsize=24)\n",
    "        plt.plot(xc, yc, '--b', label='Loss Validate')\n",
    "    if typeData == \"val_accuracy\":\n",
    "        plt.figure(2, figsize=(10, 5))\n",
    "        yc = hist.history['val_accuracy']\n",
    "        for i in range(0, len(yc)):\n",
    "            yc[i] = 100 * yc[i]\n",
    "        xc = range(epochs)\n",
    "        plt.ylabel('Accuracy (%)', fontsize=24)\n",
    "        plt.plot(xc, yc, '--b', label='Training Validate')\n",
    "\n",
    "    plt.rc('xtick', labelsize=24)\n",
    "    plt.rc('ytick', labelsize=24)\n",
    "    plt.rc('legend', fontsize=18)\n",
    "    plt.legend()\n",
    "    plt.xlabel('Number of Epochs', fontsize=24)\n",
    "    plt.grid(True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\LENOVO LEGION Y545\\PycharmProjects\\TransferLearning\\Mobilenet.ipynb Celda 10\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/LENOVO%20LEGION%20Y545/PycharmProjects/TransferLearning/Mobilenet.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m plotTraining(model_history,epocas,\u001b[39m\"\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/LENOVO%20LEGION%20Y545/PycharmProjects/TransferLearning/Mobilenet.ipynb#X12sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m plotTraining(model_history,epocas,\u001b[39m\"\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/LENOVO%20LEGION%20Y545/PycharmProjects/TransferLearning/Mobilenet.ipynb#X12sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m plotTraining(model_history,epocas,\u001b[39m\"\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model_history' is not defined"
     ]
    }
   ],
   "source": [
    "plotTraining(model_history,epocas,\"loss\")\n",
    "plotTraining(model_history,epocas,\"accuracy\")\n",
    "plotTraining(model_history,epocas,\"val_loss\")\n",
    "plotTraining(model_history,epocas,\"val_accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.5) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4052: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\LENOVO LEGION Y545\\PycharmProjects\\TransferLearning\\Mobilenet.ipynb Celda 11\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/LENOVO%20LEGION%20Y545/PycharmProjects/TransferLearning/Mobilenet.ipynb#X13sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m#modelt = custom_vgg_model\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/LENOVO%20LEGION%20Y545/PycharmProjects/TransferLearning/Mobilenet.ipynb#X13sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m imaget_path \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmelanoma3.jpg\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/LENOVO%20LEGION%20Y545/PycharmProjects/TransferLearning/Mobilenet.ipynb#X13sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m imaget\u001b[39m=\u001b[39mcv2\u001b[39m.\u001b[39;49mresize(cv2\u001b[39m.\u001b[39;49mimread(imaget_path), (width_shape, height_shape), interpolation \u001b[39m=\u001b[39;49m cv2\u001b[39m.\u001b[39;49mINTER_AREA)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/LENOVO%20LEGION%20Y545/PycharmProjects/TransferLearning/Mobilenet.ipynb#X13sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mprint\u001b[39m(imaget)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/LENOVO%20LEGION%20Y545/PycharmProjects/TransferLearning/Mobilenet.ipynb#X13sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m xt \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(imaget)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.5) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4052: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from keras.applications.imagenet_utils import preprocess_input, decode_predictions\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "width_shape = 224\n",
    "height_shape = 224\n",
    "\n",
    "names = ['MELANOMA', 'NO_MELANOMA']\n",
    "\n",
    "modelt = load_model(\"./modelos/model_Mobilenet.h5\")\n",
    "#modelt = custom_vgg_model\n",
    "\n",
    "imaget_path = \"melanoma3.jpg\"\n",
    "imaget=cv2.resize(cv2.imread(imaget_path), (width_shape, height_shape), interpolation = cv2.INTER_AREA)\n",
    "print(imaget)\n",
    "xt = np.asarray(imaget)\n",
    "xt=preprocess_input(xt)\n",
    "xt = np.expand_dims(xt,axis=0)\n",
    "preds = modelt.predict(xt)\n",
    "print(preds)\n",
    "print(names[np.argmax(preds)])\n",
    "\n",
    "\n",
    "plt.imshow(cv2.cvtColor(np.asarray(imaget),cv2.COLOR_BGR2RGB))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3560 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO LEGION Y545\\AppData\\Local\\Temp\\ipykernel_18300\\96138456.py:30: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  predictions = custom_Model.predict_generator(generator=test_generator)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9643    0.8955    0.9286      1780\n",
      "           1     0.9025    0.9669    0.9336      1780\n",
      "\n",
      "    accuracy                         0.9312      3560\n",
      "   macro avg     0.9334    0.9312    0.9311      3560\n",
      "weighted avg     0.9334    0.9312    0.9311      3560\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, f1_score, roc_curve, precision_score, recall_score, accuracy_score, roc_auc_score\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn import metrics\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "width_shape = 224\n",
    "height_shape = 224 # tamano al cual vamos a procesar las imagenes\n",
    "batch_size = 3\n",
    "\n",
    "names = ['MELANOMA','NO_MELANOMA']\n",
    "\n",
    "test_data_dir = './data/test'\n",
    "test_datagen = ImageDataGenerator()\n",
    "    \n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    target_size=(width_shape, height_shape),\n",
    "    batch_size = batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False)\n",
    "\n",
    "custom_Model= load_model(\"./modelos/model_Mobilenet.h5\")\n",
    "\n",
    "predictions = custom_Model.predict_generator(generator=test_generator)\n",
    "\n",
    "y_pred = np.argmax(predictions, axis=1)\n",
    "y_real = test_generator.classes\n",
    "\n",
    "matc=confusion_matrix(y_real, y_pred)\n",
    "\n",
    "plot_confusion_matrix(conf_mat=matc, figsize=(7,7), class_names = names, show_normed=False)\n",
    "plt.tight_layout()\n",
    "\n",
    "print(metrics.classification_report(y_real,y_pred, digits = 4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "52634da84371cba311ea128a5ea7cdc41ff074b781779e754b270ff9f8153cee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
